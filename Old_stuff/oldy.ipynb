{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all needed functions\n",
    "import os\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import glob\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "from Tools import tools\n",
    "from Calculating_det_angles import estimate_source_angles_detectors #importing ma'ams function\n",
    "\n",
    "# Replace 'path/to/your/file.html' with the path to your HTML file\n",
    "html_file_path = r\"C:\\Users\\arpan\\Downloads\\SFLAREs.html\" # this\n",
    "html_string = tools.extract_strings_html(html_file_path)\n",
    "\n",
    "event_list = []\n",
    "# getting only the event names\n",
    "for entry in html_string:\n",
    "    if 'bn' in entry:\n",
    "        event_list.append(entry)\n",
    "\n",
    "# list of events and transient type and data set name\n",
    "event_list = event_list[16:21]\n",
    "transient_type = 'SFLARE'\n",
    "data_set_name = '21.01-5_'\n",
    "\n",
    "# list of bin sizes\n",
    "bin_list = [0.001,0.005,0.01,0.1,0.5,1,5]\n",
    "\n",
    "# time interval around trigger\n",
    "ti = [-10,100]\n",
    "\n",
    "dir_path = tools.json_path(r'data_path.json')\n",
    "\n",
    "event = 'bn140518709'\n",
    "\n",
    "year = '20'+event[2:4]+\"/\"\n",
    "\n",
    "# creating a temperary folder to download the data before processing into .txt files\n",
    "temp_path = r\"C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\GRB_bn140518709\"\n",
    "\n",
    "# Finding Trigdat file\n",
    "trig_string = \"_trigdat_\"\n",
    "trig_pattern = os.path.join(temp_path,'current', f\"*{trig_string}*\")\n",
    "trigdat_file = glob.glob(trig_pattern)\n",
    "\n",
    "# Get the spacecraft pointing from here \n",
    "event_filename = trigdat_file[0]\n",
    "\n",
    "# Getting the RA and DEC\n",
    "with fits.open(event_filename, memmap=True) as pha_list:\n",
    "    ra_obj,dec_obj = (pha_list[0].header['RA_OBJ']) ,\t(pha_list[0].header['DEC_OBJ'])\n",
    "\n",
    "trap = io.StringIO()\n",
    "with redirect_stdout(trap):\n",
    "    brightest_nai, bright_nais, brightest_bgo = estimate_source_angles_detectors.angle_to_grb(ra_obj,dec_obj,event_filename) # Getting the values\n",
    "\n",
    "# Use the glob module to search for TTE files in the directory\n",
    "target_string = \"_tte_\"\n",
    "file_pattern = os.path.join(temp_path,'current', f\"*{target_string}*\")\n",
    "NaI_detector = glob.glob(file_pattern)\n",
    "\n",
    "print('NaI_detector used',NaI_detector[0])\n",
    "\n",
    "# fetchinng data\n",
    "with fits.open(NaI_detector[0], memmap=True) as hdul:\n",
    "    energy_channel_data = hdul[1].data.copy()\n",
    "    all_count_data = np.array(hdul[2].data.copy())\n",
    "\n",
    "# getting counts accross all energy channels\n",
    "counts = [float(sublist[0]) for sublist in all_count_data]\n",
    "\n",
    "data_array = []\n",
    "\n",
    "for i in bin_list:\n",
    "    # Define the range and number of bins\n",
    "    range_min = ti[0]\n",
    "    range_max = ti[-1]\n",
    "        \n",
    "    bin_size = i\n",
    "\n",
    "    # Create bin edges\n",
    "    bin_edges = np.arange(range_min, range_max, bin_size)\n",
    "\n",
    "    # Create the histogram using numpy.histogram\n",
    "    hist, edges = np.histogram(counts, bins=bin_edges)\n",
    "\n",
    "    data_array = data_array + list(hist)\n",
    "\n",
    "data_array = np.array(data_array)\n",
    "\n",
    "\n",
    "print(data_array)\n",
    "print(data_array.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all needed functions\n",
    "import os\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import glob\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "from Tools import tools\n",
    "from Calculating_det_angles import estimate_source_angles_detectors #importing ma'ams function\n",
    "\n",
    "dir_path = tools.json_path(r'data_path.json')\n",
    "data_set_path = os.path.join(dir_path, r'100_data_set')\n",
    "for index,row in df_100.iterrows():\n",
    "    temp_path = os.path.join(dir_path, r'temp')\n",
    "    tools.create_folder(temp_path)\n",
    "\n",
    "    event = row['name']\n",
    "    year = '20'+event[2:4]+\"/\"\n",
    "\n",
    "    # URL of the file you want to download\n",
    "    url = 'wget -q -nH --no-check-certificate --cut-dirs=7 -r -l0 -c -N -np -A \"*_trigdat_*\" -R \"index\"* -erobots=off --retr-symlinks https://heasarc.gsfc.nasa.gov/FTP/fermi/data/gbm/triggers/'+year+event+'/current/'\n",
    "    tools.run_wget_download(url,temp_path)\n",
    "\n",
    "    # Finding Trigdat file\n",
    "    trig_string = \"_trigdat_\"\n",
    "    trig_pattern = os.path.join(temp_path,'current', f\"*{trig_string}*\")\n",
    "    trigdat_file = glob.glob(trig_pattern)\n",
    "\n",
    "    # Get the spacecraft pointing from here \n",
    "    event_filename = trigdat_file[0]\n",
    "\n",
    "    # Getting the RA and DEC\n",
    "    with fits.open(event_filename, memmap=True) as pha_list:\n",
    "        ra_obj,dec_obj = (pha_list[0].header['RA_OBJ']) ,\t(pha_list[0].header['DEC_OBJ'])\n",
    "\n",
    "    trap = io.StringIO()\n",
    "    with redirect_stdout(trap):\n",
    "        brightest_nai, bright_nais, brightest_bgo = estimate_source_angles_detectors.angle_to_grb(ra_obj,dec_obj,event_filename) # Getting the values\n",
    "\n",
    "    # URL of the tte file to download\n",
    "    url = 'wget -q -nH --no-check-certificate --cut-dirs=7 -r -l0 -c -N -np -A \"*_tte_'+brightest_nai+'_*\" -R \"index\"* -erobots=off --retr-symlinks https://heasarc.gsfc.nasa.gov/FTP/fermi/data/gbm/triggers/'+year+event+'/current/'\n",
    "    # Construct the wget command\n",
    "    tools.run_wget_download(url,os.path.join(data_set_path,row ['event_type'] + '_' + event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all needed functions\n",
    "import os\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import glob\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "from Calculating_det_angles import estimate_source_angles_detectors #importing ma'ams function\n",
    "from Tools import tools\n",
    "\n",
    "# name of the data set\n",
    "source_data_set_path = r\"C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\100_data_set\"\n",
    "\n",
    "# Get a list of all folders in the specified directory\n",
    "folders = [str(folder) for folder in os.listdir(source_data_set_path) if os.path.isdir(os.path.join(source_data_set_path, folder))]\n",
    "\n",
    "\n",
    "# list of bin sizes\n",
    "bin_list = [0.001,0.005,0.01,0.1,0.5,1,5]\n",
    "\n",
    "# time interval around trigger\n",
    "ti = [-50,150]\n",
    "t = ti[1] - ti[0]\n",
    "\n",
    "# number of datapoints in a light curve\n",
    "data_no = t / min(bin_list)\n",
    "print(data_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all needed functions\n",
    "import os\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import glob\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "from Calculating_det_angles import estimate_source_angles_detectors #importing ma'ams function\n",
    "from Tools import tools\n",
    "\n",
    "# name of the data set\n",
    "source_data_set_path = r\"C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\100_data_set\"\n",
    "\n",
    "# Get a list of all folders in the specified directory\n",
    "folders = [str(folder) for folder in os.listdir(source_data_set_path) if os.path.isdir(os.path.join(source_data_set_path, folder))]\n",
    "\n",
    "\n",
    "# list of bin sizes\n",
    "bin_list = [0.001,0.005,0.01,0.1,0.5,1,5]\n",
    "\n",
    "# time interval around trigger\n",
    "ti = [-50,150]\n",
    "t = ti[1] - ti[0]\n",
    "\n",
    "# number of datapoints in a light curve\n",
    "data_no = int(t / min(bin_list)) \n",
    "print('number of data point' , data_no)\n",
    " \n",
    "dir_path = tools.json_path(r'data_path.json')\n",
    "data_set_name = \"data_set_1_proccessed\"\n",
    "\n",
    "# creating the data set folder\n",
    "data_set_path = os.path.join(dir_path,data_set_name)\n",
    "tools.create_folder(data_set_path)\n",
    "for folder in folders:\n",
    "    try:\n",
    "        event_type,event = folder.split(\"_\")\n",
    "        year = '20'+event[2:4]+\"/\"\n",
    "\n",
    "        # Use the glob module to search for TTE files in the directory\n",
    "        target_string = \"_tte_\"\n",
    "        file_pattern = os.path.join(source_data_set_path,folder,'current', f\"*{target_string}*\")\n",
    "        NaI_detector = glob.glob(file_pattern)\n",
    "\n",
    "        print('NaI_detector used',NaI_detector[0])\n",
    "\n",
    "        # fetchinng data\n",
    "        with fits.open(NaI_detector[0], memmap=True) as hdul:\n",
    "            energy_channel_data = hdul[1].data.copy()\n",
    "            all_count_data = np.array(hdul[2].data.copy())\n",
    "\n",
    "        # getting counts accross all energy channels\n",
    "        counts = [float(sublist[0]) for sublist in all_count_data]\n",
    "\n",
    "        data_array = []\n",
    "\n",
    "        for i in bin_list:\n",
    "            # Define the range and number of bins\n",
    "            range_min = ti[0]\n",
    "            range_max = ti[1]\n",
    "                \n",
    "            bin_size = i\n",
    "\n",
    "            f = data_no * i / t\n",
    "        \n",
    "            # Create bin edges\n",
    "            bin_edges = np.arange(range_min, range_max, bin_size)\n",
    "\n",
    "            # Create the histogram using numpy.histogram\n",
    "            hist, edges = np.histogram(counts, bins=bin_edges)\n",
    "            hist = list(hist)\n",
    "            hist.append(sum(hist)/len(hist))\n",
    "            hist = np.array(hist)\n",
    "            hist = np.repeat(hist,f)\n",
    "            data_array.append(hist)\n",
    "\n",
    "        data_array = np.array(data_array)\n",
    "\n",
    "        # Save the 2D array to a text file\n",
    "        data = os.path.join(data_set_path,event_type+'_'+event)\n",
    "        np.savetxt(data, data_array, fmt='%d', delimiter='\\t')\n",
    "        print('saved to', data)\n",
    "    except Exception as e:\n",
    "        print(f'error {e} in ',folder)\n",
    "\n",
    "\n",
    "print('\\n----------------------------------------------------------------------------\\n\\nevents', folders, ' in folder', data_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all needed functions\n",
    "import os\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import glob\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "from Calculating_det_angles import estimate_source_angles_detectors #importing ma'ams function\n",
    "from Tools import tools\n",
    "\n",
    "# name of the data set\n",
    "source_data_set_path = r\"C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\100_data_set\"\n",
    "\n",
    "# Get a list of all folders in the specified directory\n",
    "folders = [str(folder) for folder in os.listdir(source_data_set_path) if os.path.isdir(os.path.join(source_data_set_path, folder))]\n",
    "\n",
    "\n",
    "# list of bin sizes\n",
    "bin_list = [0.001,0.005,0.01,0.1,0.5,1,5]\n",
    "\n",
    "# time interval around trigger\n",
    "ti = [-50,150]\n",
    "t = ti[1] - ti[0]\n",
    "\n",
    "# number of datapoints in a light curve\n",
    "data_no = int(t / min(bin_list)) \n",
    "print('number of data point' , data_no)\n",
    " \n",
    "dir_path = tools.json_path(r'data_path.json')\n",
    "data_set_name = \"data_set_1_proccessed\"\n",
    "\n",
    "# creating the data set folder\n",
    "data_set_path = os.path.join(dir_path,data_set_name)\n",
    "tools.create_folder(data_set_path)\n",
    "for folder in folders:\n",
    "    try:\n",
    "        event_type,event = folder.split(\"_\")\n",
    "        year = '20'+event[2:4]+\"/\"\n",
    "\n",
    "        # Use the glob module to search for TTE files in the directory\n",
    "        target_string = \"_tte_\"\n",
    "        file_pattern = os.path.join(source_data_set_path,folder,'current', f\"*{target_string}*\")\n",
    "        NaI_detector = glob.glob(file_pattern)\n",
    "\n",
    "        print('NaI_detector used',NaI_detector[0])\n",
    "\n",
    "        # fetchinng data\n",
    "        with fits.open(NaI_detector[0], memmap=True) as hdul:\n",
    "            energy_channel_data = hdul[1].data.copy()\n",
    "            all_count_data = np.array(hdul[2].data.copy())\n",
    "\n",
    "        # getting counts accross all energy channels\n",
    "        counts = [float(sublist[0]) for sublist in all_count_data]\n",
    "\n",
    "        data_array = []\n",
    "\n",
    "        for i in bin_list:\n",
    "            # Define the range and number of bins\n",
    "            range_min = ti[0]\n",
    "            range_max = ti[1]\n",
    "                \n",
    "            bin_size = i\n",
    "\n",
    "            f = data_no * i / t\n",
    "        \n",
    "            # Create bin edges\n",
    "            bin_edges = np.arange(range_min, range_max, bin_size)\n",
    "\n",
    "            # Create the histogram using numpy.histogram\n",
    "            hist, edges = np.histogram(counts, bins=bin_edges)\n",
    "            hist = list(hist)\n",
    "            hist.append(sum(hist)/len(hist))\n",
    "            hist = np.array(hist)\n",
    "            hist = np.repeat(hist,f)\n",
    "            data_array.append(hist)\n",
    "\n",
    "        data_array = np.array(data_array)\n",
    "\n",
    "        # Save the 2D array to a text file\n",
    "        data = os.path.join(data_set_path,event_type+'_'+event)\n",
    "        np.savetxt(data, data_array, fmt='%d', delimiter='\\t')\n",
    "        print('saved to', data)\n",
    "    except Exception as e:\n",
    "        print(f'error {e} in ',folder)\n",
    "\n",
    "\n",
    "print('\\n----------------------------------------------------------------------------\\n\\nevents', folders, ' in folder', data_set_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
