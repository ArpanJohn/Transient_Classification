{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all needed functions\n",
    "import os\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "from astropy.io import fits\n",
    "import glob\n",
    "from Calculating_det_angles import estimate_source_angles_detectors  # Importing ma'am's function\n",
    "from Tools import tools\n",
    "import threading\n",
    "from queue import Queue\n",
    "import queue\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6372 entries, 0 to 6371\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   event_name   6372 non-null   object \n",
      " 1   event_type   6372 non-null   object \n",
      " 2   reliability  6372 non-null   float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 149.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_set_path = r\"D:\\GRB_data\\500_data_set\"\n",
    "df = pd.read_csv('all_events.csv')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value to remove\n",
    "value_to_remove = 'SFL'\n",
    "\n",
    "# Filter to keep rows where 'col1' is not equal to the value to remove\n",
    "df = df[df['event_type'] != value_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_type\n",
      "GRB       2710\n",
      "SFLARE    1611\n",
      "TGF       1386\n",
      "SGR        492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the number of entries for each unique value\n",
    "value_counts = df['event_type'].value_counts()\n",
    "\n",
    "# Print the value counts\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_type</th>\n",
       "      <th>reliability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bn221109533</td>\n",
       "      <td>SGR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bn220709626</td>\n",
       "      <td>SGR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bn221204313</td>\n",
       "      <td>SGR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bn160727543</td>\n",
       "      <td>SGR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bn220626269</td>\n",
       "      <td>SGR</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    event_name event_type  reliability\n",
       "0  bn221109533        SGR          1.0\n",
       "1  bn220709626        SGR          1.0\n",
       "2  bn221204313        SGR          1.0\n",
       "3  bn160727543        SGR          1.0\n",
       "4  bn220626269        SGR          1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shuffle the DataFrame\n",
    "# df_shuffled = df.sample(frac=1, random_state=42)  # Set random_state for reproducibility\n",
    "\n",
    "# event_counter = {'GRB': 0, 'SFLARE': 0, 'TGF': 0, 'SGR': 0}\n",
    "# event_limit = 2000\n",
    "\n",
    "# # Get a list of all folders in the specified directory\n",
    "# folders = [folder for folder in os.listdir(data_set_path) if os.path.isdir(os.path.join(data_set_path, folder))]\n",
    "\n",
    "# folder_names = []\n",
    "# for folder in folders:\n",
    "#     if folder.split('_')[0] in event_counter.keys():\n",
    "#         bn_name = folder.split('_')[0]\n",
    "#         event_counter[bn_name] += 1\n",
    "#         folder_names.append(folder.split('_')[1])\n",
    "\n",
    "# print(\"events already downloaded\\n\", event_counter)\n",
    "\n",
    "# event_counter = {'GRB': 0, 'SFLARE': 0, 'TGF': 0, 'SGR': 0}\n",
    "# event_type, name = [], []\n",
    "\n",
    "# for index, row in df_shuffled.iterrows():\n",
    "#     f = 0\n",
    "#     for folder in folders:\n",
    "#         bn_name = folder.split('_')[1]\n",
    "#         if bn_name == row['event_name']:\n",
    "#             event_counter[row['event_type']] += 1\n",
    "#             f = 1\n",
    "#             break\n",
    "\n",
    "#     if f == 1:\n",
    "#         continue\n",
    "\n",
    "#     if row['event_type'] in event_counter and not (row['event_name'] in folder_names):\n",
    "#         if event_counter[row['event_type']] < event_limit:\n",
    "#             event_counter[row['event_type']] += 1\n",
    "#             event_type.append(row['event_type'])\n",
    "#             name.append(row['event_name'])\n",
    "\n",
    "# print('events to download\\n',event_counter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events already downloaded\n",
      " {'GRB': 1655, 'SFLARE': 1085, 'SGR': 492, 'TGF': 1142}\n",
      "events to download\n",
      " {'SFLARE': 15}\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the DataFrame\n",
    "df_shuffled = df.sample(frac=1, random_state=42)  # Set random_state for reproducibility\n",
    "\n",
    "event_limit = 1100\n",
    "\n",
    "# Get a list of all folders in the specified directory\n",
    "folders = [folder for folder in os.listdir(data_set_path) if os.path.isdir(os.path.join(data_set_path, folder))]\n",
    "\n",
    "# Create sets for faster lookup\n",
    "folder_set = set(folders)\n",
    "event_types = set(['GRB', 'SFLARE', 'TGF', 'SGR'])\n",
    "\n",
    "# Count events already downloaded\n",
    "downloaded_events = Counter(folder.split('_')[0] for folder in folders if folder.split('_')[0] in event_types)\n",
    "print(\"events already downloaded\\n\", dict(downloaded_events))\n",
    "\n",
    "# Create set of existing event names for faster lookup\n",
    "existing_event_names = set(folder.split('_')[1] for folder in folders)\n",
    "\n",
    "# Initialize counters for events to download\n",
    "events_to_download = Counter()\n",
    "\n",
    "# Lists to store new events\n",
    "new_event_types = []\n",
    "new_event_names = []\n",
    "\n",
    "for _, row in df_shuffled.iterrows():\n",
    "    event_type = row['event_type']\n",
    "    event_name = row['event_name']\n",
    "\n",
    "    if event_type in event_types and event_name not in existing_event_names:\n",
    "        if events_to_download[event_type] < event_limit - downloaded_events[event_type]:\n",
    "            events_to_download[event_type] += 1\n",
    "            new_event_types.append(event_type)\n",
    "            new_event_names.append(event_name)\n",
    "\n",
    "print('events to download\\n', dict(events_to_download))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(new_event_types))\n",
    "print(len(new_event_names))\n",
    "\n",
    "event_list  = new_event_names\n",
    "event_types = new_event_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn130405735\n",
      "SFLARE\n"
     ]
    }
   ],
   "source": [
    "print(event_list[0])\n",
    "print(event_types[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3492\n",
      "3492\n",
      "events already downloaded\n",
      " {}\n",
      "events to download\n",
      " {'SFLARE': 1000, 'TGF': 1000, 'SGR': 492, 'GRB': 1000}\n"
     ]
    }
   ],
   "source": [
    "# reading the ttsplit file\n",
    "df = pd.read_csv('ttsplit')\n",
    "\n",
    "# getting the test and train events\n",
    "test_events = df[df['category'] == 'test']['filename'].tolist()\n",
    "\n",
    "train_events = df[df['category'] == 'train']['filename'].tolist()\n",
    "\n",
    "# loading the event names and event types in the list\n",
    "\n",
    "event_names = []\n",
    "event_types = []\n",
    "\n",
    "for _,row in df.iterrows():\n",
    "    if (row[\"category\"] == \"test\" or row[\"category\"] == \"train\") and row[\"filename\"][-1] != 'd':\n",
    "        event_type,event_name = row['filename'].split(\"_\")\n",
    "        event_types.append(event_type)\n",
    "        event_names.append(event_name)\n",
    "\n",
    "print(len(event_names))\n",
    "print(len(event_types))\n",
    "\n",
    "\n",
    "data_set_path = r\"D:\\GRB_data\\new_dataset\"\n",
    "\n",
    "# Get a list of all folders in the specified directory\n",
    "folders = [folder for folder in os.listdir(data_set_path) if os.path.isdir(os.path.join(data_set_path, folder))]\n",
    "\n",
    "# Create sets for faster lookup\n",
    "folder_set = set(folders)\n",
    "event_types = set(['GRB', 'SFLARE', 'TGF', 'SGR'])\n",
    "\n",
    "# Count events already downloaded\n",
    "downloaded_events = Counter(folder.split('_')[0] for folder in folders if folder.split('_')[0] in event_types)\n",
    "print(\"events already downloaded\\n\", dict(downloaded_events))\n",
    "\n",
    "# Create set of existing event names for faster lookup\n",
    "existing_event_names = set(folder.split('_')[1] for folder in folders)\n",
    "\n",
    "# Initialize counters for events to download\n",
    "events_to_download = Counter()\n",
    "\n",
    "# Lists to store new events\n",
    "new_event_types = []\n",
    "new_event_names = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    event_type,event_name = row['filename'].split(\"_\")\n",
    "    if (row[\"category\"] == \"test\" or row[\"category\"] == \"train\") and row[\"filename\"][-1] != 'd':\n",
    "        if event_type in event_types and event_name not in existing_event_names:\n",
    "            if events_to_download[event_type] < event_limit - downloaded_events[event_type]:\n",
    "                events_to_download[event_type] += 1\n",
    "                new_event_types.append(event_type)\n",
    "                new_event_names.append(event_name)\n",
    "\n",
    "print('events to download\\n', dict(events_to_download))\n",
    "\n",
    "\n",
    "event_names = new_event_names\n",
    "event_types = new_event_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn140204646\n",
      "SFLARE\n"
     ]
    }
   ],
   "source": [
    "print(event_names[0])\n",
    "print(event_types[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker thread 0 started.\n",
      "Worker thread 1 started.\n",
      "2\n",
      "Worker thread 0 processing event SFLARE bn140204646.\n",
      "C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\temp0\n",
      "Worker thread 1 processing event TGF bn190821888.\n",
      "C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\temp1\n",
      "Folder 'C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\temp0' already exists.\n",
      "Folder 'C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\temp1' already exists.\n",
      "Folder 'C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\temp1' and its contents removed successfully.\n",
      "Folder 'C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\temp0' and its contents removed successfully.\n",
      "Folder 'C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\temp0' created successfully.\n",
      "download start\n",
      "Folder 'C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\temp1' created successfully.\n",
      "download start\n",
      "Downloaded bn140204646_trigdat_ to C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\temp0\n",
      "download start\n",
      "Downloaded bn190821888_trigdat_ to C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\temp1\n",
      "download start\n",
      "Downloaded bn190821888.rsp to C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\temp1\n",
      " \n",
      "The brightest NaI detector is nb - Source angle is: 65 deg\n",
      "The brightest 3 NaI detectors are nb ( 65 deg) n8 ( 73 deg) na ( 81 deg)\n",
      "The brightest BGO detector is b1 ( 66 deg )\n",
      "download start\n",
      "Downloaded bn140204646.rsp to C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\temp0\n",
      " \n",
      "The brightest NaI detector is n0 - Source angle is: 42 deg\n",
      "The brightest 3 NaI detectors are n0 ( 42 deg) n4 ( 64 deg) n2 ( 65 deg)\n",
      "The brightest BGO detector is b0 ( 35 deg )\n",
      "download start\n",
      "Downloaded bn190821888_tte_nb_ to D:\\GRB_data\\new_dataset\\TGF_bn190821888\n",
      "0\n",
      "Worker thread 1 processed event bn190821888.\n",
      "Worker thread 1 finished.\n",
      "Downloaded bn140204646_tte_n0_ to D:\\GRB_data\\new_dataset\\SFLARE_bn140204646\n",
      "0\n",
      "Worker thread 0 processed event bn140204646.\n",
      "Worker thread 0 finished.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dir_path = tools.json_path(r'data_path.json')\n",
    "\n",
    "# Function to process a single event\n",
    "def process_event(event_name, event_type,thread_num):\n",
    "    try:\n",
    "        temp_thread = r'temp'+ str(thread_num)\n",
    "        temp_path = os.path.join(dir_path, temp_thread)\n",
    "        print(temp_path)\n",
    "        tools.create_folder(temp_path)\n",
    "        event = event_name\n",
    "        year = '20' + event[2:4] + \"/\"\n",
    "\n",
    "        # URL of the file you want to download : TRIGDAT file\n",
    "        url = 'wget -q -nH --no-check-certificate --cut-dirs=7 -r -l0 -c -N -np -A \"*_trigdat_*\" -R \"index*\" -erobots=off --retr-symlinks https://heasarc.gsfc.nasa.gov/FTP/fermi/data/gbm/triggers/' + year + event + '/current/'\n",
    "        tools.run_wget_download(url, temp_path)\n",
    "\n",
    "        # Finding Trigdat file\n",
    "        trig_string = \"_trigdat_\"\n",
    "        trig_pattern = os.path.join(temp_path, 'current', f\"*{trig_string}*\")\n",
    "        trigdat_file = glob.glob(trig_pattern)\n",
    "\n",
    "        # Get the spacecraft pointing from here\n",
    "        trigdat_filename = trigdat_file[0]\n",
    "\n",
    "        # URL of the file you want to download : .rsp file\n",
    "        url = 'wget -q -nH --no-check-certificate --cut-dirs=7 -r -l0 -c -N -np -A \"*.rsp*\" -R \"index*\" -erobots=off --retr-symlinks https://heasarc.gsfc.nasa.gov/FTP/fermi/data/gbm/triggers/' + year + event + '/current/'\n",
    "        tools.run_wget_download(url, temp_path)\n",
    "\n",
    "        # Finding .rsp file\n",
    "        rsp_string = \".rsp\"\n",
    "        rsp_pattern = os.path.join(temp_path, 'current', f\"*{trig_string}*\")\n",
    "        rsp_file = glob.glob(trig_pattern)\n",
    "\n",
    "        # Getting the RA and DEC\n",
    "        with fits.open(rsp_file[0], memmap=True) as pha_list:\n",
    "            ra_obj, dec_obj = (pha_list[0].header['RA_OBJ']), (pha_list[0].header['DEC_OBJ'])\n",
    "\n",
    "        brightest_nai, bright_nais, brightest_bgo,nai_angles = estimate_source_angles_detectors.angle_to_grb(ra_obj, dec_obj,trigdat_filename)\n",
    "\n",
    "        for nai_angle,nai in zip(nai_angles,bright_nais):\n",
    "            if nai == brightest_nai or int(nai_angle) < 60: # only download the brightest detector or if the detector has anlge less than 60 deg\n",
    "                # URL of the tte file to download\n",
    "                url = 'wget -q -nH --no-check-certificate --cut-dirs=7 -r -l0 -c -N -np -A \"*_tte_' + nai + '_*\" -R \"index*\" -erobots=off --retr-symlinks https://heasarc.gsfc.nasa.gov/FTP/fermi/data/gbm/triggers/' + year + event + '/current/'\n",
    "\n",
    "                # Construct the wget command\n",
    "                tools.run_wget_download(url, os.path.join(data_set_path, event_type + '_' + event))\n",
    "        # Print the size of the queue\n",
    "        print(event_queue.qsize()) \n",
    "\n",
    "    except Exception as e:\n",
    "        # Get formatted traceback\n",
    "        traceback_str = traceback.format_exc()\n",
    "\n",
    "        # Access exception attributes (example)\n",
    "        if isinstance(e, ZeroDivisionError):\n",
    "            error_details = \"Division by zero attempted.\"\n",
    "        else:\n",
    "            error_details = str(e.args[0]) if len(e.args) else \"Unknown error.\"\n",
    "\n",
    "        # Custom message based on exception type\n",
    "        if isinstance(e, ValueError):\n",
    "            custom_message = \"Invalid value provided. Check your input data.\"\n",
    "        else:\n",
    "            custom_message = \"An error occurred during processing.\"\n",
    "\n",
    "        # Print detailed message\n",
    "        print(f\"\"\"Error:\n",
    "        - Event: {event_name}\n",
    "        - Exception: {type(e).__name__}\n",
    "        - Message: {e}\n",
    "        - Details: {error_details}\n",
    "        - Traceback:\n",
    "        {traceback_str}\n",
    "        - {custom_message}\"\"\")\n",
    "\n",
    "# Create a queue to store the events\n",
    "event_queue = Queue()\n",
    "\n",
    "# Function to run the worker threads\n",
    "def worker(thread_num):\n",
    "    print(f\"Worker thread {thread_num} started.\")\n",
    "\n",
    "    while True : #\n",
    "        # Get an event from the queue\n",
    "        event_name, event_type = event_queue.get()\n",
    "        print(f\"Worker thread {thread_num} processing event {event_type} {event_name}.\")\n",
    "\n",
    "        # Process the event\n",
    "        process_event(event_name, event_type,thread_num)\n",
    "\n",
    "        # Signal that the task is completed\n",
    "        event_queue.task_done()\n",
    "        print(f\"Worker thread {thread_num} processed event {event_name}.\")\n",
    "\n",
    "        if event_queue.qsize() == 0:\n",
    "            break\n",
    "    \n",
    "    print(f\"Worker thread {thread_num} finished.\")\n",
    "    \n",
    "# Create and start the worker threads\n",
    "num_threads = 2\n",
    "threads = []\n",
    "for i in range(num_threads):\n",
    "    worker_thread = threading.Thread(target=worker, args=(i,), daemon=True)\n",
    "    worker_thread.start()\n",
    "    threads.append(worker_thread)\n",
    "\n",
    "# Add events to the queue\n",
    "for event_name, event_type in zip(event_names[:2], event_types[:32]):\n",
    "    event_queue.put((event_name, event_type))\n",
    "\n",
    "print(event_queue.qsize()) \n",
    "\n",
    "# # Wait for all events to be processed\n",
    "# event_queue.join()\n",
    "# print(\"All events have been processed.\")\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
