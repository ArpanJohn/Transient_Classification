{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d38899f0-2d08-47b3-839f-770d6e870c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCL CNN\n",
    "\n",
    "# importing all needed functions\n",
    "import os\n",
    "from pathlib import Path\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "from Tools import tools\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "import os\n",
    "import shutil\n",
    "import line_profiler\n",
    "from scipy import stats\n",
    "from line_profiler import profile\n",
    "%load_ext line_profiler\n",
    "import pwkit.bblocks\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Polyfit may be poorly conditioned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "913a9917-2b43-48f7-8b8d-a428af0caff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['UNRELOC_bn170416538', 'UNRELOC_bn210829572', 'UNRELOC_bn200404757', 'UNRELOC_bn140512120', 'UNRELOC_bn170830825', 'UNRELOC_bn171104946', 'UNRELOC_bn170422447', 'UNRELOC_bn150916829', 'UNRELOC_bn201217806', 'UNRELOC_bn150917079']\n"
     ]
    }
   ],
   "source": [
    "# reading the ttsplit file\n",
    "df = pd.read_csv(r\"C:\\Users\\arpan\\Downloads\\uncertain.txt\")\n",
    "\n",
    "# getting the test and train events\n",
    "test_events = df[df['category'] == 'test']['filename'].tolist()\n",
    "print(test_events[:10])  \n",
    "\n",
    "train_events = df[df['category'] == 'train']['filename'].tolist()\n",
    "print(train_events[:10])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d7ff5c7-5a57-4604-9439-6bc9bd0c4f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_files = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "692b3a8e-a2a7-4065-9658-484ce0d3d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_folders(directory, folder_list):\n",
    "    for folder in folder_list:\n",
    "        folder_path = os.path.join(directory, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            try:\n",
    "                shutil.rmtree(folder_path)\n",
    "                print(f\"Deleted folder: {folder}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting folder {folder}: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"{folder} is not a folder or does not exist.\")\n",
    "\n",
    "@jit(nopython=True)\n",
    "def filter_counts(times, channels, min_ch, max_ch, trigtime):\n",
    "    \"\"\"\n",
    "    Filter count data based on channel range and subtract trigtime.\n",
    "    \n",
    "    :param times: Array of event times\n",
    "    :param channels: Array of channel numbers\n",
    "    :param min_ch: Minimum channel number\n",
    "    :param max_ch: Maximum channel number\n",
    "    :param trigtime: Trigger time to be subtracted\n",
    "    :return: Filtered and adjusted count data\n",
    "    \"\"\"\n",
    "    counts = []\n",
    "    for t, ch in zip(times, channels):\n",
    "        if min_ch <= ch <= max_ch:\n",
    "            counts.append(t - trigtime)\n",
    "    return np.array(counts)\n",
    "\n",
    "@profile\n",
    "def process_folder(folder, bin_list,data_no,r,chrs,data_set_path,source_data_set_path,error_folders,inup=False,zero_files = zero_files, plot = False):\n",
    "    \"\"\"\n",
    "    Process a single folder of data.\n",
    "    \n",
    "    :param folder: Name of the folder to process\n",
    "    :param bin_list: List of bin sizes to use\n",
    "    \"\"\"\n",
    "    # try:\n",
    "    # Extract event information from folder name\n",
    "    event_type, event = folder.split(\"_\")\n",
    "\n",
    "    mod_folder = folder[:-1] if folder [-1] == 'd' else folder\n",
    "\n",
    "\n",
    "    # check if the file is processed\n",
    "    data_file_path = Path(data_set_path) / f\"{event_type}_{event}\"\n",
    "    if data_file_path.exists():\n",
    "        # print(f\"File already processed: {data_file_path}\")\n",
    "        return\n",
    "\n",
    "    # Construct file pattern and find matching files\n",
    "    file_pattern = str(Path(source_data_set_path) / mod_folder / 'current' / '*_tte_*')\n",
    "    NaI_detector = glob.glob(file_pattern)\n",
    "\n",
    "    # changes to accomodate multiple tte files. test this:\n",
    "    counts_list = []\n",
    "    # print(data_file_path)\n",
    "    for nai in NaI_detector:\n",
    "        # print(f\"nai det {nai}\")\n",
    "        # Read data from FITS file\n",
    "        with fits.open(nai, memmap=True) as hdul:\n",
    "            all_count_data = hdul[2].data\n",
    "            trigtime = float(hdul[2].header['TRIGTIME'])\n",
    "\n",
    "        # Extract times and channels from all_count_data\n",
    "        times = all_count_data['TIME'].astype(float)\n",
    "        channels = all_count_data['PHA'].astype(int)\n",
    "\n",
    "        # print('len times',len(times))\n",
    "        # print('len chennels',len(channels))\n",
    "\n",
    "\n",
    "        for ranges in chrs:\n",
    "            # Filter counts for different channel ranges\n",
    "            counts_list.append(filter_counts(times, channels, ranges[0], ranges[1], trigtime))       \n",
    "\n",
    "\n",
    "    # putting the counts from different detector into one array\n",
    "    new_counts_list = []\n",
    "    for i in range(len(chrs)):  # for each energy bin\n",
    "        # Get counts for this energy bin from all detectors and concatenate them\n",
    "        bin_concat = np.concatenate([counts_list[j] for j in range(i, len(counts_list), len(chrs))])\n",
    "        new_counts_list.append(bin_concat)\n",
    "\n",
    "    counts_list = new_counts_list\n",
    "\n",
    "    data_array = []\n",
    "    \n",
    "    # Process both count ranges\n",
    "    for i in bin_list:\n",
    "        sep_sig = []\n",
    "        ch_no = 1\n",
    "        for counts in counts_list:\n",
    "            # Calculate range and bin size\n",
    "            range_min = -data_no * i * r\n",
    "            range_max = data_no * i * (1-r)\n",
    "            bin_size = i\n",
    "\n",
    "            # print(range_max)\n",
    "            # print(range_min)\n",
    "\n",
    "            # Create histogram\n",
    "            bin_edges = np.arange(range_min, range_max, bin_size)\n",
    "            hist, edges = np.histogram(counts, bins=bin_edges)\n",
    "            hist = adjust_zeros(hist)\n",
    "            bin_widths = edges[1:]-edges[:-1]\n",
    "            hrates = hist / bin_size\n",
    "\n",
    "            up_rates = hrates # unprocessed rates\n",
    "            if inup:\n",
    "                sep_sig.extend(up_rates)\n",
    "                continue\n",
    "\n",
    "            # Perform Bayesian Block Analysis\n",
    "            bayes = pwkit.bblocks.bin_bblock(widths = bin_widths, counts = hist, p0 = 0.01)\n",
    "\n",
    "            # Getting the results of the analysis\n",
    "            block_starts = (bayes.get('blockstarts') * i) + range_min\n",
    "            block_stops = block_starts + bayes.get('widths')\n",
    "            bins = np.array(list(block_starts) + list([block_stops[-1]]))\n",
    "            rates = bayes.get('rates')\n",
    "\n",
    "            # Find indices where rates are non-zero\n",
    "            non_zero_indices = np.nonzero(rates)[0]\n",
    "            \n",
    "            # Select rates that are non-zero\n",
    "            rates = rates[non_zero_indices]\n",
    "            \n",
    "            try:\n",
    "                # Select corresponding bins\n",
    "                bins = np.concatenate([bins[non_zero_indices], [bins[non_zero_indices[-1] + 1]]])\n",
    "            except:\n",
    "                bins = [0,0,0,0]\n",
    "                \n",
    "            sigw = bins[-2] - bins[1]\n",
    "\n",
    "            bk2 = bins[1] - (5 * bin_size)\n",
    "            bk3 = bins[-2] + (5 * bin_size)\n",
    "            bk1 = bk2 - sigw - (50 * bin_size) if (bk2 - sigw - (50 * bin_size)) > bins[0] else bins[0]\n",
    "            bk4 = bk3 + sigw + (50 * bin_size) if (bk3 + sigw + (50 * bin_size)) < bins[-1] else bins[-1]\n",
    "\n",
    "            # bk2 = bins[1]  # \n",
    "            # bk3 = bins[-2] # \n",
    "            # bk1 = bins[0]  # \n",
    "            # bk4 = bins[-1] # \n",
    "            \n",
    "            bkgd = [(bk1,bk2),(bk3,bk4)]\n",
    "\n",
    "            # Check if background is proper\n",
    "            bkgd_check = bk1<bk2<bk3<bk4\n",
    "\n",
    "            # Checking for signal\n",
    "            # Checks False alarm probability p0, number of bins, and if background is detected around trigger\n",
    "            if bayes.get('finalp0') >= 0.05 or len(bins)<4 or not(bk2 - 5 <= 0 <= bk3 + 5) or not bkgd_check:\n",
    "                if plot:\n",
    "                    print('no signal')\n",
    "                    plt.stairs(hrates, edges)\n",
    "                    plt.show()\n",
    "                    plt.stairs(rates, bins)\n",
    "                    plt.show()\n",
    "                # print('no signal')\n",
    "                # print(i,ch_no)\n",
    "                signal = np.zeros(data_no-1).astype(np.int32) # send no signal\n",
    "                                \n",
    "            else:\n",
    "                y = hrates\n",
    "                x = (edges[1:] + edges[:-1]) / 2\n",
    "                bkgd_pol,_ = best_fit_polynomial(x, y, bkgd)\n",
    "\n",
    "                # Create mask for y between bk2 and bk3\n",
    "                mask = (x >= bk2) & (x <= bk3)\n",
    "\n",
    "                # Apply the mask and take the maximum of 0 and y - bkgd_pol(x)\n",
    "                signal = np.zeros(data_no-1).astype(np.int32)\n",
    "                signal[mask] = np.maximum(0, (y[mask] - bkgd_pol(x[mask]))).astype(np.int32)\n",
    "                \n",
    "                if plot:\n",
    "                    # Plot the results\n",
    "                    plt.stairs(hrates,edges)\n",
    "                    plt.xlabel('Time (s)')\n",
    "                    plt.ylabel('rates')\n",
    "                    plt.title(f'light curve ; ch = {ch_no} ;bin size = {bin_size}s')\n",
    "                    # Plot each shaded area\n",
    "                    for i, (x1, x2) in enumerate(bkgd):\n",
    "                        plt.axvspan(x1, x2, alpha=0.3, color='red',label = 'background selection') \n",
    "                    # make sure most things are visible\n",
    "                    if min(edges) < counts.min():\n",
    "                        plt.gca().set_xlim(left=counts.min())\n",
    "                    if max(edges) > counts.max():\n",
    "                        plt.gca().set_xlim(right=counts.max())\n",
    "                    plt.axvline(x=0, color='red', linestyle='--', linewidth=0.5)\n",
    "                    # Evaluate the background polynomial for plotting\n",
    "                    bkgd_y = bkgd_pol(x)\n",
    "                    \n",
    "                    # Check if the background blows up\n",
    "                    if np.any(np.abs(bkgd_y) > 10 * np.max(np.abs(y))) or np.any(np.abs(bkgd_y) < 0.1 * np.min(np.abs(y[y != 0]))):                \n",
    "                        # Plot the background within the limits\n",
    "                        mask = (bkgd_y >= plt.ylim()[0]) & (bkgd_y <= plt.ylim()[1])\n",
    "                        plt.plot(x[mask], bkgd_y[mask], '--', label='background')\n",
    "                    else:\n",
    "                        # If it doesn't blow up, plot normally\n",
    "                        plt.plot(x, bkgd_y, '--', label='background')\n",
    "                    plt.show()\n",
    "\n",
    "                    # signal plot\n",
    "                    plt.title(f'light curve ; ch = {ch_no} ;bin size = {bin_size}s')\n",
    "                    plt.axvline(x=0, color='red', linestyle='--', linewidth=0.5)\n",
    "                    plt.xlabel('Time (s)')\n",
    "                    plt.ylabel('rates')\n",
    "                    plt.plot(x,signal)\n",
    "                    plt.show()\n",
    "\n",
    "            # updatae channel number and save signal\n",
    "            ch_no = ch_no + 1               \n",
    "            sep_sig.extend(signal)\n",
    "            \n",
    "\n",
    "        # Accumulate histogram data\n",
    "        data_array.extend(sep_sig)\n",
    "\n",
    "    # Convert accumulated data to numpy array\n",
    "    data_array = np.array(data_array)\n",
    "\n",
    "    extra = 1 if inup else 1 # inup change\n",
    "    if data_array.shape[0] != (len(bin_list)) * (len(chrs)*extra) * (data_no-1):\n",
    "        print('something may have gone wrong in ', folder)\n",
    "        print(data_array.shape[0], (len(bin_list)) * (len(chrs)*(extra)) * (data_no-1))\n",
    "        print(type(data_array.shape[0]), type((len(bin_list)) * (len(chrs)*(extra)) * (data_no-1)))\n",
    "        print(data_array.shape[0] != (len(bin_list)) * (len(chrs)+extra) * (data_no-1))\n",
    "    \n",
    "    if plot:\n",
    "        print('shape', data_array.shape)\n",
    "\n",
    "    if np.all(data_array == 0):\n",
    "        zero_files = zero_files + 1\n",
    "\n",
    "    # print('shape', data_array.shape)\n",
    "\n",
    "    # Save data to file\n",
    "    with open(data_file_path, 'w') as f:\n",
    "        np.savetxt(f, data_array, fmt='%d', delimiter='')\n",
    "        # print(f\"Data saved to {data_file_path}\")\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     # Handle and log any errors\n",
    "    #     print(f'error {e} in {folder}')\n",
    "    #     # traceback.print_exc()\n",
    "    #     error_folders.append(folder)     \n",
    "\n",
    "    return zero_files   \n",
    "\n",
    "def adjust_zeros(arr):\n",
    "    # Create a copy of the input array\n",
    "    result = np.copy(arr)\n",
    "    \n",
    "    # Find first non-zero element\n",
    "    first_non_zero = np.argmax(arr != 0)\n",
    "    \n",
    "    # Find last non-zero element\n",
    "    last_non_zero = len(arr) - np.argmax(arr[::-1] != 0) - 1\n",
    "    \n",
    "    # Replace value after leading zeros with zero if there are leading zeros\n",
    "    if first_non_zero > 0:\n",
    "        result[first_non_zero] = 0\n",
    "    \n",
    "    # Replace value before trailing zeros with zero if there are trailing zeros\n",
    "    if last_non_zero < len(arr) - 1:\n",
    "        result[last_non_zero] = 0\n",
    "    \n",
    "    return result\n",
    "\n",
    "def best_fit_polynomial(x, y, background_intervals):\n",
    "    # Filter data to include only background intervals\n",
    "    mask = np.zeros(len(x), dtype=bool)\n",
    "    for start, end in background_intervals:\n",
    "        mask |= (x >= start) & (x <= end)\n",
    "    \n",
    "    x_bg = x[mask]\n",
    "    y_bg = y[mask]\n",
    "    \n",
    "    best_order = 0\n",
    "    best_polynomial = None\n",
    "    best_r_squared = -np.inf\n",
    "    \n",
    "    for order in range(1, 5):  # Test polynomials of order 1 to 4\n",
    "        coeffs = np.polyfit(x_bg, y_bg, order)\n",
    "        p = np.poly1d(coeffs)\n",
    "        \n",
    "        # Calculate R-squared\n",
    "        y_pred = p(x_bg)\n",
    "        r_squared = 1 - np.sum((y_bg - y_pred)**2) / np.sum((y_bg - np.mean(y_bg))**2)\n",
    "        \n",
    "        # Perform F-test to compare with lower order model\n",
    "        if order > 1:\n",
    "            f_statistic = ((r_squared - prev_r_squared) / (order - prev_order)) / \\\n",
    "                          ((1 - r_squared) / (len(x_bg) - order - 1))\n",
    "            p_value = 1 - stats.f.cdf(f_statistic, 1, len(x_bg) - order - 1)\n",
    "            \n",
    "            if p_value < 0.05 and r_squared > best_r_squared:\n",
    "                best_order = order\n",
    "                best_polynomial = p\n",
    "                best_r_squared = r_squared\n",
    "        else:\n",
    "            best_order = order\n",
    "            best_polynomial = p\n",
    "            best_r_squared = r_squared\n",
    "        \n",
    "        prev_order = order\n",
    "        prev_r_squared = r_squared\n",
    "    \n",
    "    return best_polynomial, best_order\n",
    "\n",
    "def full_plot(x,y,bkgd,bkgd_pol,peak = 0,peak_time = 0):\n",
    "        # Create the plot\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.plot(x,y,label = 'data')\n",
    "\n",
    "        # Plot each shaded area\n",
    "        for i, (x1, x2) in enumerate(bkgd):\n",
    "            plt.axvspan(x1, x2, alpha=0.3, color='red',label = 'background selection') \n",
    "        \n",
    "        check_poly = np.poly1d([0,1])\n",
    "        if not np.all(bkgd_pol.coef == check_poly.coef):\n",
    "            # Evaluate the background polynomial\n",
    "            bkgd_y = bkgd_pol(x)\n",
    "            \n",
    "            # Check if the background blows up\n",
    "            if np.any(np.abs(bkgd_y) > 10 * np.max(np.abs(y))) or np.any(np.abs(bkgd_y) < 0.1 * np.min(np.abs(y[y != 0]))):                \n",
    "                # Plot the background within the limits\n",
    "                mask = (bkgd_y >= plt.ylim()[0]) & (bkgd_y <= plt.ylim()[1])\n",
    "                plt.plot(x[mask], bkgd_y[mask], '--', label='background')\n",
    "            else:\n",
    "                # If it doesn't blow up, plot normally\n",
    "                plt.plot(x, bkgd_y, '--', label='background')\n",
    "        \n",
    "        # If it blows up, limit the y-axis\n",
    "        y_min, y_max = np.min(y), np.max(y)\n",
    "        y_range = y_max - y_min\n",
    "        plt.ylim(y_min - 0.1*y_range, y_max + 0.1*y_range)\n",
    "        plt.axvline(x=0,ls='--' ,alpha = 0.5, linewidth=1)\n",
    "\n",
    "        if peak == 0 and peak_time == 0:\n",
    "            pass\n",
    "        else:\n",
    "            plt.scatter(peak_time,peak, s=40, c='k', marker='*', label='peak')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70e3d17b-ace3-4e68-9b12-ba4074891d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 50), (51, 124)]\n",
      "Folder 'C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\DCL_test' already exists.\n",
      "delete C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\DCL_test y/n?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\DCL_test' and its contents removed successfully.\n",
      "Folder 'C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\DCL_test' created successfully.\n",
      "Folder 'C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\DCL_test\\test' created successfully.\n",
      "Folder 'C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\DCL_test\\train' created successfully.\n",
      "Folder 'C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\DCL_test\\other' created successfully.\n",
      "start\n",
      "total :  90\n",
      "Data has been written to C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\DCL_test\\params.json\n",
      "saving processed events to  C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\DCL_test\\test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing folders: 0folder [00:00, ?folder/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving processed events to  C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\DCL_test\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing folders: 100%|██████████| 75/75 [01:14<00:00,  1.01folder/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 73.73 s\n",
      "File: C:\\Users\\arpan\\AppData\\Local\\Temp\\ipykernel_11384\\2168863051.py\n",
      "Function: process_folder at line 31\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    31                                           @profile\n",
      "    32                                           def process_folder(folder, bin_list,data_no,r,chrs,data_set_path,source_data_set_path,error_folders,inup=False,zero_files = zero_files, plot = False):\n",
      "    33                                               \"\"\"\n",
      "    34                                               Process a single folder of data.\n",
      "    35                                               \n",
      "    36                                               :param folder: Name of the folder to process\n",
      "    37                                               :param bin_list: List of bin sizes to use\n",
      "    38                                               \"\"\"\n",
      "    39                                               # try:\n",
      "    40                                               # Extract event information from folder name\n",
      "    41        75       2977.0     39.7      0.0      event_type, event = folder.split(\"_\")\n",
      "    42                                           \n",
      "    43        75       1132.0     15.1      0.0      mod_folder = folder[:-1] if folder [-1] == 'd' else folder\n",
      "    44                                           \n",
      "    45                                           \n",
      "    46                                               # check if the file is processed\n",
      "    47        75      96179.0   1282.4      0.0      data_file_path = Path(data_set_path) / f\"{event_type}_{event}\"\n",
      "    48        75     159123.0   2121.6      0.0      if data_file_path.exists():\n",
      "    49                                                   # print(f\"File already processed: {data_file_path}\")\n",
      "    50                                                   return\n",
      "    51                                           \n",
      "    52                                               # Construct file pattern and find matching files\n",
      "    53        75     132859.0   1771.5      0.0      file_pattern = str(Path(source_data_set_path) / mod_folder / 'current' / '*_tte_*')\n",
      "    54        75     407935.0   5439.1      0.1      NaI_detector = glob.glob(file_pattern)\n",
      "    55                                           \n",
      "    56                                               # changes to accomodate multiple tte files. test this:\n",
      "    57        75        622.0      8.3      0.0      counts_list = []\n",
      "    58                                               # print(data_file_path)\n",
      "    59       231       2947.0     12.8      0.0      for nai in NaI_detector:\n",
      "    60                                                   # print(f\"nai det {nai}\")\n",
      "    61                                                   # Read data from FITS file\n",
      "    62       156    6958523.0  44605.9      0.9          with fits.open(nai, memmap=True) as hdul:\n",
      "    63       156   21304835.0 136569.5      2.9              all_count_data = hdul[2].data\n",
      "    64       156     685491.0   4394.2      0.1              trigtime = float(hdul[2].header['TRIGTIME'])\n",
      "    65                                           \n",
      "    66                                                   # Extract times and channels from all_count_data\n",
      "    67       156   12549594.0  80446.1      1.7          times = all_count_data['TIME'].astype(float)\n",
      "    68       156    3240118.0  20770.0      0.4          channels = all_count_data['PHA'].astype(int)\n",
      "    69                                           \n",
      "    70                                                   # print('len times',len(times))\n",
      "    71                                                   # print('len chennels',len(channels))\n",
      "    72                                           \n",
      "    73                                           \n",
      "    74       468      13027.0     27.8      0.0          for ranges in chrs:\n",
      "    75                                                       # Filter counts for different channel ranges\n",
      "    76       312   37370297.0 119776.6      5.1              counts_list.append(filter_counts(times, channels, ranges[0], ranges[1], trigtime))       \n",
      "    77                                           \n",
      "    78                                           \n",
      "    79                                               # putting the counts from different detector into one array\n",
      "    80        75       1098.0     14.6      0.0      new_counts_list = []\n",
      "    81       225       7786.0     34.6      0.0      for i in range(len(chrs)):  # for each energy bin\n",
      "    82                                                   # Get counts for this energy bin from all detectors and concatenate them\n",
      "    83       150    2207523.0  14716.8      0.3          bin_concat = np.concatenate([counts_list[j] for j in range(i, len(counts_list), len(chrs))])\n",
      "    84       150       5616.0     37.4      0.0          new_counts_list.append(bin_concat)\n",
      "    85                                           \n",
      "    86        75     523805.0   6984.1      0.1      counts_list = new_counts_list\n",
      "    87                                           \n",
      "    88        75       2118.0     28.2      0.0      data_array = []\n",
      "    89                                               \n",
      "    90                                               # Process both count ranges\n",
      "    91       600       9219.0     15.4      0.0      for i in bin_list:\n",
      "    92       525      10733.0     20.4      0.0          sep_sig = []\n",
      "    93       525       3243.0      6.2      0.0          ch_no = 1\n",
      "    94      1575      19851.0     12.6      0.0          for counts in counts_list:\n",
      "    95                                                       # Calculate range and bin size\n",
      "    96      1050      18474.0     17.6      0.0              range_min = -data_no * i * r\n",
      "    97      1050      15201.0     14.5      0.0              range_max = data_no * i * (1-r)\n",
      "    98      1050       6045.0      5.8      0.0              bin_size = i\n",
      "    99                                           \n",
      "   100                                                       # print(range_max)\n",
      "   101                                                       # print(range_min)\n",
      "   102                                           \n",
      "   103                                                       # Create histogram\n",
      "   104      1050      82061.0     78.2      0.0              bin_edges = np.arange(range_min, range_max, bin_size)\n",
      "   105      1050   78671561.0  74925.3     10.7              hist, edges = np.histogram(counts, bins=bin_edges)\n",
      "   106      1050     651856.0    620.8      0.1              hist = adjust_zeros(hist)\n",
      "   107      1050      49546.0     47.2      0.0              bin_widths = edges[1:]-edges[:-1]\n",
      "   108      1050      90106.0     85.8      0.0              hrates = hist / bin_size\n",
      "   109                                           \n",
      "   110      1050       8952.0      8.5      0.0              up_rates = hrates # unprocessed rates\n",
      "   111      1050       5553.0      5.3      0.0              if inup:\n",
      "   112                                                           sep_sig.extend(up_rates)\n",
      "   113                                                           continue\n",
      "   114                                           \n",
      "   115                                                       # Perform Bayesian Block Analysis\n",
      "   116      1050  524211052.0 499248.6     71.1              bayes = pwkit.bblocks.bin_bblock(widths = bin_widths, counts = hist, p0 = 0.01)\n",
      "   117                                           \n",
      "   118                                                       # Getting the results of the analysis\n",
      "   119      1050     126466.0    120.4      0.0              block_starts = (bayes.get('blockstarts') * i) + range_min\n",
      "   120      1050      39819.0     37.9      0.0              block_stops = block_starts + bayes.get('widths')\n",
      "   121      1050     190879.0    181.8      0.0              bins = np.array(list(block_starts) + list([block_stops[-1]]))\n",
      "   122      1050      27400.0     26.1      0.0              rates = bayes.get('rates')\n",
      "   123                                           \n",
      "   124                                                       # Find indices where rates are non-zero\n",
      "   125      1050     131079.0    124.8      0.0              non_zero_indices = np.nonzero(rates)[0]\n",
      "   126                                                       \n",
      "   127                                                       # Select rates that are non-zero\n",
      "   128      1050      18313.0     17.4      0.0              rates = rates[non_zero_indices]\n",
      "   129                                                       \n",
      "   130      1050       6179.0      5.9      0.0              try:\n",
      "   131                                                           # Select corresponding bins\n",
      "   132      1050     132251.0    126.0      0.0                  bins = np.concatenate([bins[non_zero_indices], [bins[non_zero_indices[-1] + 1]]])\n",
      "   133         8         47.0      5.9      0.0              except:\n",
      "   134         8        108.0     13.5      0.0                  bins = [0,0,0,0]\n",
      "   135                                                           \n",
      "   136      1050      18516.0     17.6      0.0              sigw = bins[-2] - bins[1]\n",
      "   137                                           \n",
      "   138      1050      22867.0     21.8      0.0              bk2 = bins[1] - (5 * bin_size)\n",
      "   139      1050      14845.0     14.1      0.0              bk3 = bins[-2] + (5 * bin_size)\n",
      "   140      1050      24580.0     23.4      0.0              bk1 = bk2 - sigw - (50 * bin_size) if (bk2 - sigw - (50 * bin_size)) > bins[0] else bins[0]\n",
      "   141      1050      19516.0     18.6      0.0              bk4 = bk3 + sigw + (50 * bin_size) if (bk3 + sigw + (50 * bin_size)) < bins[-1] else bins[-1]\n",
      "   142                                           \n",
      "   143                                                       # bk2 = bins[1]  # \n",
      "   144                                                       # bk3 = bins[-2] # \n",
      "   145                                                       # bk1 = bins[0]  # \n",
      "   146                                                       # bk4 = bins[-1] # \n",
      "   147                                                       \n",
      "   148      1050      14636.0     13.9      0.0              bkgd = [(bk1,bk2),(bk3,bk4)]\n",
      "   149                                           \n",
      "   150                                                       # Check if background is proper\n",
      "   151      1050       9857.0      9.4      0.0              bkgd_check = bk1<bk2<bk3<bk4\n",
      "   152                                           \n",
      "   153                                                       # Checking for signal\n",
      "   154                                                       # Checks False alarm probability p0, number of bins, and if background is detected around trigger\n",
      "   155      1050      42119.0     40.1      0.0              if bayes.get('finalp0') >= 0.05 or len(bins)<4 or not(bk2 - 5 <= 0 <= bk3 + 5) or not bkgd_check:\n",
      "   156       864       7312.0      8.5      0.0                  if plot:\n",
      "   157                                                               print('no signal')\n",
      "   158                                                               plt.stairs(hrates, edges)\n",
      "   159                                                               plt.show()\n",
      "   160                                                               plt.stairs(rates, bins)\n",
      "   161                                                               plt.show()\n",
      "   162                                                           # print('no signal')\n",
      "   163                                                           # print(i,ch_no)\n",
      "   164       864      65707.0     76.0      0.0                  signal = np.zeros(data_no-1).astype(np.int32) # send no signal\n",
      "   165                                                                           \n",
      "   166                                                       else:\n",
      "   167       186       1606.0      8.6      0.0                  y = hrates\n",
      "   168       186      20134.0    108.2      0.0                  x = (edges[1:] + edges[:-1]) / 2\n",
      "   169       186    5293482.0  28459.6      0.7                  bkgd_pol,_ = best_fit_polynomial(x, y, bkgd)\n",
      "   170                                           \n",
      "   171                                                           # Create mask for y between bk2 and bk3\n",
      "   172       186      21378.0    114.9      0.0                  mask = (x >= bk2) & (x <= bk3)\n",
      "   173                                           \n",
      "   174                                                           # Apply the mask and take the maximum of 0 and y - bkgd_pol(x)\n",
      "   175       186      16196.0     87.1      0.0                  signal = np.zeros(data_no-1).astype(np.int32)\n",
      "   176       186     115754.0    622.3      0.0                  signal[mask] = np.maximum(0, (y[mask] - bkgd_pol(x[mask]))).astype(np.int32)\n",
      "   177                                                           \n",
      "   178       186       1543.0      8.3      0.0                  if plot:\n",
      "   179                                                               # Plot the results\n",
      "   180                                                               plt.stairs(hrates,edges)\n",
      "   181                                                               plt.xlabel('Time (s)')\n",
      "   182                                                               plt.ylabel('rates')\n",
      "   183                                                               plt.title(f'light curve ; ch = {ch_no} ;bin size = {bin_size}s')\n",
      "   184                                                               # Plot each shaded area\n",
      "   185                                                               for i, (x1, x2) in enumerate(bkgd):\n",
      "   186                                                                   plt.axvspan(x1, x2, alpha=0.3, color='red',label = 'background selection') \n",
      "   187                                                               # make sure most things are visible\n",
      "   188                                                               if min(edges) < counts.min():\n",
      "   189                                                                   plt.gca().set_xlim(left=counts.min())\n",
      "   190                                                               if max(edges) > counts.max():\n",
      "   191                                                                   plt.gca().set_xlim(right=counts.max())\n",
      "   192                                                               plt.axvline(x=0, color='red', linestyle='--', linewidth=0.5)\n",
      "   193                                                               # Evaluate the background polynomial for plotting\n",
      "   194                                                               bkgd_y = bkgd_pol(x)\n",
      "   195                                                               \n",
      "   196                                                               # Check if the background blows up\n",
      "   197                                                               if np.any(np.abs(bkgd_y) > 10 * np.max(np.abs(y))) or np.any(np.abs(bkgd_y) < 0.1 * np.min(np.abs(y[y != 0]))):                \n",
      "   198                                                                   # Plot the background within the limits\n",
      "   199                                                                   mask = (bkgd_y >= plt.ylim()[0]) & (bkgd_y <= plt.ylim()[1])\n",
      "   200                                                                   plt.plot(x[mask], bkgd_y[mask], '--', label='background')\n",
      "   201                                                               else:\n",
      "   202                                                                   # If it doesn't blow up, plot normally\n",
      "   203                                                                   plt.plot(x, bkgd_y, '--', label='background')\n",
      "   204                                                               plt.show()\n",
      "   205                                           \n",
      "   206                                                               # signal plot\n",
      "   207                                                               plt.title(f'light curve ; ch = {ch_no} ;bin size = {bin_size}s')\n",
      "   208                                                               plt.axvline(x=0, color='red', linestyle='--', linewidth=0.5)\n",
      "   209                                                               plt.xlabel('Time (s)')\n",
      "   210                                                               plt.ylabel('rates')\n",
      "   211                                                               plt.plot(x,signal)\n",
      "   212                                                               plt.show()\n",
      "   213                                           \n",
      "   214                                                       # updatae channel number and save signal\n",
      "   215      1050      10824.0     10.3      0.0              ch_no = ch_no + 1               \n",
      "   216      1050     307416.0    292.8      0.0              sep_sig.extend(signal)\n",
      "   217                                                       \n",
      "   218                                           \n",
      "   219                                                   # Accumulate histogram data\n",
      "   220       525      38506.0     73.3      0.0          data_array.extend(sep_sig)\n",
      "   221                                           \n",
      "   222                                               # Convert accumulated data to numpy array\n",
      "   223        75     388037.0   5173.8      0.1      data_array = np.array(data_array)\n",
      "   224                                           \n",
      "   225        75        797.0     10.6      0.0      extra = 1 if inup else 1 # inup change\n",
      "   226        75       3447.0     46.0      0.0      if data_array.shape[0] != (len(bin_list)) * (len(chrs)*extra) * (data_no-1):\n",
      "   227                                                   print('something may have gone wrong in ', folder)\n",
      "   228                                                   print(data_array.shape[0], (len(bin_list)) * (len(chrs)*(extra)) * (data_no-1))\n",
      "   229                                                   print(type(data_array.shape[0]), type((len(bin_list)) * (len(chrs)*(extra)) * (data_no-1)))\n",
      "   230                                                   print(data_array.shape[0] != (len(bin_list)) * (len(chrs)+extra) * (data_no-1))\n",
      "   231                                               \n",
      "   232        75        601.0      8.0      0.0      if plot:\n",
      "   233                                                   print('shape', data_array.shape)\n",
      "   234                                           \n",
      "   235        75      36029.0    480.4      0.0      if np.all(data_array == 0):\n",
      "   236        23        277.0     12.0      0.0          zero_files = zero_files + 1\n",
      "   237                                           \n",
      "   238                                               # print('shape', data_array.shape)\n",
      "   239                                           \n",
      "   240                                               # Save data to file\n",
      "   241        75     608690.0   8115.9      0.1      with open(data_file_path, 'w') as f:\n",
      "   242        75   39995061.0 533267.5      5.4          np.savetxt(f, data_array, fmt='%d', delimiter='')\n",
      "   243                                                   # print(f\"Data saved to {data_file_path}\")\n",
      "   244                                           \n",
      "   245                                               # except Exception as e:\n",
      "   246                                               #     # Handle and log any errors\n",
      "   247                                               #     print(f'error {e} in {folder}')\n",
      "   248                                               #     # traceback.print_exc()\n",
      "   249                                               #     error_folders.append(folder)     \n",
      "   250                                           \n",
      "   251        75        849.0     11.3      0.0      return zero_files   \n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "events ['BELOWHZ_bn091216359', 'BELOWHZ_bn110808375', 'BELOWHZ_bn120315329', 'BELOWHZ_bn120605953', 'BELOWHZ_bn120617678', 'BELOWHZ_bn121115044', 'BELOWHZ_bn130628931', 'BELOWHZ_bn130816205', 'BELOWHZ_bn130828248', 'BELOWHZ_bn160317596', 'BELOWHZ_bn170528148', 'BELOWHZ_bn171019218', 'BELOWHZ_bn180911647', 'BELOWHZ_bn220606952', 'BELOWHZ_bn220828664', 'UNCERT_bn091022752', 'UNCERT_bn100303194', 'UNCERT_bn100402447', 'UNCERT_bn100617514', 'UNCERT_bn100729415', 'UNCERT_bn100909220', 'UNCERT_bn101027186', 'UNCERT_bn110519623', 'UNCERT_bn110703526', 'UNCERT_bn110822775', 'UNCERT_bn120312392', 'UNCERT_bn120811712', 'UNCERT_bn120813978', 'UNCERT_bn121229590', 'UNCERT_bn121230875', 'UNCERT_bn130205970', 'UNCERT_bn130424231', 'UNCERT_bn130428054', 'UNCERT_bn131117611', 'UNCERT_bn140330899', 'UNCERT_bn150424918', 'UNCERT_bn150806630', 'UNCERT_bn150906985', 'UNCERT_bn150907725', 'UNCERT_bn160121414', 'UNCERT_bn160210750', 'UNCERT_bn160831686', 'UNCERT_bn161026169', 'UNCERT_bn170211197', 'UNCERT_bn170317705', 'UNCERT_bn170818417', 'UNCERT_bn171115576', 'UNCERT_bn171202587', 'UNCERT_bn180419951', 'UNCERT_bn181104784', 'UNCERT_bn181213038', 'UNCERT_bn190326747', 'UNCERT_bn191006575', 'UNCERT_bn191025926', 'UNCERT_bn200122414', 'UNCERT_bn210719929', 'UNCERT_bn210831148', 'UNCERT_bn211221163', 'UNCERT_bn220108026', 'UNCERT_bn220222492', 'UNCERT_bn221008657', 'UNCERT_bn230330665', 'UNCERT_bn230611568', 'UNCERT_bn240307586', 'UNCERT_bn240326553', 'UNRELOC_bn100928923', 'UNRELOC_bn120614887', 'UNRELOC_bn140219282', 'UNRELOC_bn140512120', 'UNRELOC_bn150409251', 'UNRELOC_bn150521238', 'UNRELOC_bn150916829', 'UNRELOC_bn150917079', 'UNRELOC_bn160706999', 'UNRELOC_bn161211422', 'UNRELOC_bn170416538', 'UNRELOC_bn170422447', 'UNRELOC_bn170423179', 'UNRELOC_bn170830825', 'UNRELOC_bn171027452', 'UNRELOC_bn171104946', 'UNRELOC_bn181215061', 'UNRELOC_bn190505818', 'UNRELOC_bn200404757', 'UNRELOC_bn200518800', 'UNRELOC_bn201217806', 'UNRELOC_bn210527628', 'UNRELOC_bn210807895', 'UNRELOC_bn210829572', 'UNRELOC_bn221206544']  in folder C:\\Users\\arpan\\OneDrive\\Documents\\GRB\\data\\DCL_test\n",
      "Elapsed Time: 74.25 seconds\n",
      "errors occured in:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    # name of the data set\n",
    "    source_data_set_path = r\"C:\\Users\\arpan\\Downloads\\Uncertain\\Uncertain\"\n",
    "\n",
    "    # Get a list of all folders in the specified directory\n",
    "    folders = [str(folder) for folder in os.listdir(source_data_set_path) if os.path.isdir(os.path.join(source_data_set_path, folder))]\n",
    "\n",
    "    # list of bin sizes\n",
    "    bin_list = [0.001, 0.005, 0.01, 0.1, 0.5, 1, 5]  \n",
    "\n",
    "    # number of datapoints in a light curve\n",
    "    data_no = 500\n",
    "\n",
    "    # ratio of pre-trigger to post-trigger\n",
    "    r = 0.5\n",
    "\n",
    "    # channel ranges\n",
    "    number_of_ranges = 8\n",
    "    size_of_ranges = int(128/number_of_ranges)\n",
    "    chrs = [(3,50),(51,124)]  # [(i, i + size_of_ranges-1) for i in range(0, 128, size_of_ranges)] #\n",
    "    print(chrs)\n",
    "    \n",
    "    # include unprocess data?\n",
    "    inup = False\n",
    "\n",
    "    dir_path = tools.json_path(r'data_path.json')\n",
    "    data_set_name = \"DCL_test\"\n",
    "\n",
    "    # creating the data set folder\n",
    "    data_set_path = os.path.join(dir_path,data_set_name)\n",
    "    tools.create_folder(data_set_path,carefull=True) # carefull\n",
    "\n",
    "    # creating the test and train directories\n",
    "    test_path = os.path.join(data_set_path, 'test')\n",
    "    train_path = os.path.join(data_set_path, 'train')\n",
    "    other_path = os.path.join(data_set_path, 'other')\n",
    "    tools.create_folder(test_path,carefull=True)\n",
    "    tools.create_folder(train_path,carefull=True)\n",
    "    tools.create_folder(other_path,carefull=True)\n",
    "\n",
    "    print('start')\n",
    "    print('total : ',len(folders))\n",
    "\n",
    "    # Measure execution time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Writing the parameters to a json file\n",
    "    params_dict = {\"bin list\": bin_list, \"time interval\": 'n/a', \"number of data points\": data_no-1, \"data set name\": data_set_name, \"data set path\": str(data_set_path),\n",
    "                \"channel ranges\": chrs, \"ratio\":r, \"type\": \"hrates\", \"include unprocessed\": inup}\n",
    "    write_json_file = tools.write_json_file(params_dict, os.path.join(data_set_path,'params.json'))\n",
    "\n",
    "\n",
    "    error_folders = []\n",
    "\n",
    "    profiler = line_profiler.LineProfiler()\n",
    "    profiler.add_function(process_folder)\n",
    "    profiler.enable_by_count()\n",
    "\n",
    "zero_files = 0\n",
    "\n",
    "# processing test data\n",
    "print('saving processed events to ',test_path)\n",
    "for folder in tqdm(test_events[:], desc=\"Processing folders\", unit=\"folder\"):\n",
    "   zero_files = process_folder(folder,bin_list,data_no,r,chrs,test_path,source_data_set_path,error_folders,inup, zero_files,plot=False)    \n",
    "\n",
    "# processing train data\n",
    "print('saving processed events to ',train_path)\n",
    "for folder in tqdm(train_events[:], desc=\"Processing folders\", unit=\"folder\"):\n",
    "   zero_files = process_folder(folder,bin_list,data_no,r,chrs,train_path,source_data_set_path,error_folders,inup,zero_files,plot=False)    \n",
    "\n",
    "         \n",
    "profiler.print_stats()\n",
    "print('\\n----------------------------------------------------------------------------\\n\\nevents', folders, ' in folder', data_set_path)\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "print(\"errors occured in:\")\n",
    "for folder in error_folders:\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8141517f-0881-48a6-ab53-87a2cb326ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "print(zero_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df7ce40-df94-4e43-906b-fd0b6c6ddf38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
